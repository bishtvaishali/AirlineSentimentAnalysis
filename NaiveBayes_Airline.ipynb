{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT TEST ['neutral', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'positive']\n",
      "SHAPE: (419, 1218)\n",
      "PREDICT ['positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'neutral' 'positive' 'positive'\n",
      " 'positive']\n",
      "accuracy: 0.21052631578947367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.17      1.00      0.29         3\n",
      "    negative       0.00      0.00      0.00         9\n",
      "     neutral       1.00      0.14      0.25         7\n",
      "\n",
      "   micro avg       0.21      0.21      0.21        19\n",
      "   macro avg       0.39      0.38      0.18        19\n",
      "weighted avg       0.39      0.21      0.14        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 9],\n",
       "       [0, 1, 6],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization, stemming, stop word removal\n",
    "import xlrd, re\n",
    "\n",
    "path = (\"Tweets.xls\") \n",
    "spreadSheet = xlrd.open_workbook(path)\n",
    "\n",
    "testData = []\n",
    "tweetsData = []\n",
    "sentiment = [] \n",
    "targetSentiment = [\"positive\", \"negative\",\"neutral\"]\n",
    "\n",
    "import random\n",
    "sheet1 = spreadSheet.sheet_by_index(1) \n",
    "#Training Data ------\n",
    "for x in range(1, 420):\n",
    "    i = random.randint(1,420)\n",
    "#     print(\"rndom:\" , i)\n",
    "    arrStr = re.sub('[!@#\\\"$]', \"\", sheet1.cell_value(i, 10)) \n",
    "    arrStr = re.sub(r\"\\//\\S+\", \"\", arrStr)\n",
    "    tweetsData.append(arrStr) \n",
    "    sentiment.append(sheet1.cell_value(i, 1))\n",
    "     \n",
    "# print(tweetsData)\n",
    "# print(testData)\n",
    "\n",
    "#Test Data -------\n",
    "testDict = []\n",
    "testSentiment = []\n",
    "sheet0 = spreadSheet.sheet_by_index(0) \n",
    "\n",
    "for count in range(1, 20):\n",
    "    x = random.randint(10,200)\n",
    "   \n",
    "    arrStr = re.sub('[!@#\\\"$]', \"\", sheet0.cell_value(x, 10))   \n",
    "    testDict.append(arrStr)\n",
    "    testSentiment.append(sheet0.cell_value(x, 1))\n",
    "    \n",
    "# print(\"TEST\", testDict)\n",
    "print(\"SENTIMENT TEST\", testSentiment)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "countVector = CountVectorizer()\n",
    "vocab= countVector.fit(tweetsData)\n",
    "# print(\"\\nVocabulary: \" + str(countVector.vocabulary_) + '\\n')\n",
    "# print(\"Features: \" + str(countVector.get_feature_names()) + '\\n') \n",
    "\n",
    "termCountMatrix = countVector.transform(tweetsData)\n",
    "print(\"SHAPE: \"+ str(termCountMatrix.shape)) #3 documents and 7 unique terms/vocab\n",
    "# print(\"COUNT MATRIX: \\n\"+ str(termCountMatrix.toarray())) \n",
    "\n",
    "#terms given tfIdf\n",
    "tfIdfTransformer = TfidfTransformer()\n",
    "tfIdfTransformer.fit(termCountMatrix)#sorted in the order of Features array\n",
    "# print(\"TFIDF:\" + str(tfIdfTransformer.idf_))\n",
    "\n",
    "tdIdfMatrix = tfIdfTransformer.transform(termCountMatrix)\n",
    "# print(\"TFIDF:\" + str(tdIdfMatrix.toarray()))\n",
    "\n",
    "model = MultinomialNB().fit(tdIdfMatrix,sentiment)\n",
    "# model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "# model.fit(trainDict.values(), trainDict.keys())\n",
    "# labels = model.predict(testDict.values())\n",
    "\n",
    "newVectorMatrix = countVector.transform(testDict)\n",
    "newTFMatrix =  tfIdfTransformer.transform(newVectorMatrix)\n",
    "predicted = model.predict(newTFMatrix)\n",
    "\n",
    "print(\"PREDICT\",predicted)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(testSentiment,predicted)\n",
    "print(\"accuracy:\", accuracy)\n",
    "print(metrics.classification_report(testSentiment, predicted, targetSentiment))\n",
    "metrics.confusion_matrix(testSentiment,predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
